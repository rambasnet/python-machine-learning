{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- sample features are the keys to machine learning as they determine how well a ML algorithm can learn\n",
    "- it is absolutely important that we examine and preprocess a dataset before we feed it to a ML algorithm\n",
    "- feature engineering involves from feature processing to dealing with missing values to properly encoding features and selecting the best features\n",
    "- the goal of feature engineering is simply to make your data better suited to the problem at hand plus:\n",
    "    - improve a model's predictive performance\n",
    "    - reduce computational or data needs\n",
    "    - improve interpretability of the results\n",
    "\n",
    "### Dealing with missing data\n",
    "- it's not uncommon to miss certain feature values for many reasons\n",
    "    - error in data collection process\n",
    "    - certain measurements may not be applicable\n",
    "    - particular fields  could have been simply left blank in survey\n",
    "- missing values are usually missing or blank or NaN or NULL\n",
    "- ML algorithm can result unpredictable results if we simply ignore missing values\n",
    "\n",
    "#### Identify missing values\n",
    "- first, identify missing values and deal with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = '''\n",
    "A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "10.0,11.0,12.0,\n",
    "'''\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "# StringIO function let's us read csv_data as if it's a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    1\n",
       "D    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the # of null values per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating training examples or features with missing values\n",
    "- one of the easiest way to deal with the missing data is simply to remove the feature (columns) or training examples (rows) from the dataset entirely\n",
    "- this is usually done when there's plenty of examples and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  1.0  2.0  3.0  4.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing examples; return's new DataFrame objects after dropping all the rows in NaN\n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B\n",
       "0   1.0   2.0\n",
       "1   5.0   6.0\n",
       "2  10.0  11.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows where all columns are NaN\n",
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  1.0  2.0  3.0  4.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows that have fewer than 4 real values\n",
    "df.dropna(thresh=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows where NaN appear in specific columns\n",
    "df.dropna(subset=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "- often dropping an entire feature column is not practicle\n",
    "    - we may lose some valuable information\n",
    "- we can use interploation techniques to estimate the missing values from other training examples\n",
    "\n",
    "### mean imputation\n",
    "- simply replace the missing value with the mean value of the entire feature column\n",
    "- use `SimpleImputer` class from scikit-learn - https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "- different strategies to fill missing values:\n",
    "    - mean, most_frequet, median, constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our original DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values via the column mean\n",
    "si = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "si = si.fit(df.values)\n",
    "imputed_data = si.transform(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  2. ,  3. ,  4. ],\n",
       "       [ 5. ,  6. ,  7.5,  8. ],\n",
       "       [10. , 11. , 12. ,  6. ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   7.5  8.0\n",
       "2  10.0  11.0  12.0  6.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another approach; returns a new DataFrame\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using transformed data using estimaters\n",
    "- the whole data can be transformed first and split to train and test set\n",
    "- new data must be tranformed using the same technique if the model is deployed\n",
    "![](./images/ML-Transformed-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical data\n",
    "- there are two types of categorical data\n",
    "- **ordinal**\n",
    "    - categorical values that can be sorted or ordered\n",
    "    - e.g., T-shirt size: XS < S < M < L < XL < XXL\n",
    "- **nominal**\n",
    "    - categorical values that don't imply any order\n",
    "    - e.g., color values: blue, green, etc.\n",
    "    - gender: male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['green', 'M', 10.1, 'class2'],\n",
    "                   ['red', 'L', 13.5, 'class1'],\n",
    "                   ['blue', 'XL', 15.3, 'class2']])\n",
    "\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class2\n",
       "1    red    L   13.5     class1\n",
       "2   blue   XL   15.3     class2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping ordinal features\n",
    "- no convenient function/API to derive the order of ordinal features\n",
    "- just define the mapping manually and use the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_mapping = {'M':1, 'L':2, 'XL':3}\n",
    "df['size'] = df['size'].map(size_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.1     class2\n",
       "1    red     2   13.5     class1\n",
       "2   blue     3   15.3     class2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     M\n",
       "1     L\n",
       "2    XL\n",
       "Name: size, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the original string representation\n",
    "inv_size_mapping = {v: k for k, v in size_mapping.items()}\n",
    "df['size'].map(inv_size_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding class labels\n",
    "- scikit-learn classifiers convert class labels to integers internally\n",
    "- best practice to encode class labels explictly as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding with sklearn's LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df['classlabel'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding on nominal features\n",
    "- if nominal features encoded the same way as ordinal using numeric order ML classifiers may assume order in data and may lead to not optimal results\n",
    "    - e.g. {'green': 1, 'red': 2, 'blue': 3}\n",
    "- workaround is one-hot encoding\n",
    "- create a new dummy feature for each unique value in the nominal feature column\n",
    "    - use binary values for each feature; 1 represents the feature and 0 doesn't\n",
    "- use `OneHotEncoder` function https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['color', 'size', 'price']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['green', 1, 10.1],\n",
       "       ['red', 2, 13.5],\n",
       "       ['blue', 3, 15.3]], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_ohe.fit_transform(X[:, 0].reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ColumnTransformer to transorm the whole dataset with multiple columns\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_transf = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(), [0]),\n",
    "    ('nothing', 'passthrough', [1, 2])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['green', 1, 10.1],\n",
       "       ['red', 2, 13.5],\n",
       "       ['blue', 3, 15.3]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  0. ,  1. , 10.1],\n",
       "       [ 0. ,  0. ,  1. ,  2. , 13.5],\n",
       "       [ 1. ,  0. ,  0. ,  3. , 15.3]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_transf.fit_transform(X).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  size  color_blue  color_green  color_red\n",
       "0   10.1     1           0            1          0\n",
       "1   13.5     2           0            0          1\n",
       "2   15.3     3           1            0          0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more convenient way to create dummy features via one-hot encoding is us get_dummies method in pandas\n",
    "pd.get_dummies(df[['price', 'color', 'size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.1     class2\n",
       "1    red     2   13.5     class1\n",
       "2   blue     3   15.3     class2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine dataset\n",
    "- let's apply preprocessing technqiues to Wine dataset found in UCI\n",
    "- https://archive.ics.uci.edu/ml/datasets/Wine\n",
    "- 178 wine samples with 13 features describing their different chemical properties\n",
    "- classify wine to three different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "df_wine = pd.read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3     4    5     6     7     8     9      10    11  \\\n",
       "0     1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1     1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2     1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3     1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4     1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..   ..    ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   \n",
       "173   3  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174   3  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175   3  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176   3  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177   3  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       12    13  \n",
       "0    3.92  1065  \n",
       "1    3.40  1050  \n",
       "2    3.17  1185  \n",
       "3    3.45  1480  \n",
       "4    2.93   735  \n",
       "..    ...   ...  \n",
       "173  1.74   740  \n",
       "174  1.56   750  \n",
       "175  1.56   835  \n",
       "176  1.62   840  \n",
       "177  1.60   560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                   'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Class labels [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print('Unique Class labels', np.unique(df_wine['Class label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0              1    14.23        1.71  2.43               15.6        127   \n",
       "1              1    13.20        1.78  2.14               11.2        100   \n",
       "2              1    13.16        2.36  2.67               18.6        101   \n",
       "3              1    14.37        1.95  2.50               16.8        113   \n",
       "4              1    13.24        2.59  2.87               21.0        118   \n",
       "..           ...      ...         ...   ...                ...        ...   \n",
       "173            3    13.71        5.65  2.45               20.5         95   \n",
       "174            3    13.40        3.91  2.48               23.0        102   \n",
       "175            3    13.27        4.28  2.26               20.0        120   \n",
       "176            3    13.17        2.59  2.37               20.0        120   \n",
       "177            3    14.13        4.10  2.74               24.5         96   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "175           1.59        0.69                  0.43             1.35   \n",
       "176           1.65        0.68                  0.53             1.46   \n",
       "177           2.05        0.76                  0.56             1.35   \n",
       "\n",
       "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0               5.64  1.04                          3.92     1065  \n",
       "1               4.38  1.05                          3.40     1050  \n",
       "2               5.68  1.03                          3.17     1185  \n",
       "3               7.80  0.86                          3.45     1480  \n",
       "4               4.32  1.04                          2.93      735  \n",
       "..               ...   ...                           ...      ...  \n",
       "173             7.70  0.64                          1.74      740  \n",
       "174             7.30  0.70                          1.56      750  \n",
       "175            10.20  0.59                          1.56      835  \n",
       "176             9.30  0.60                          1.62      840  \n",
       "177             9.20  0.61                          1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class label                     0\n",
       "Alcohol                         0\n",
       "Malic acid                      0\n",
       "Ash                             0\n",
       "Alcalinity of ash               0\n",
       "Magnesium                       0\n",
       "Total phenols                   0\n",
       "Flavanoids                      0\n",
       "Nonflavanoid phenols            0\n",
       "Proanthocyanins                 0\n",
       "Color intensity                 0\n",
       "Hue                             0\n",
       "OD280/OD315 of diluted wines    0\n",
       "Proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check for null or missing values\n",
    "df_wine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class label     Alcohol  Malic acid         Ash  Alcalinity of ash  \\\n",
       "count   178.000000  178.000000  178.000000  178.000000         178.000000   \n",
       "mean      1.938202   13.000618    2.336348    2.366517          19.494944   \n",
       "std       0.775035    0.811827    1.117146    0.274344           3.339564   \n",
       "min       1.000000   11.030000    0.740000    1.360000          10.600000   \n",
       "25%       1.000000   12.362500    1.602500    2.210000          17.200000   \n",
       "50%       2.000000   13.050000    1.865000    2.360000          19.500000   \n",
       "75%       3.000000   13.677500    3.082500    2.557500          21.500000   \n",
       "max       3.000000   14.830000    5.800000    3.230000          30.000000   \n",
       "\n",
       "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
       "count  178.000000     178.000000  178.000000            178.000000   \n",
       "mean    99.741573       2.295112    2.029270              0.361854   \n",
       "std     14.282484       0.625851    0.998859              0.124453   \n",
       "min     70.000000       0.980000    0.340000              0.130000   \n",
       "25%     88.000000       1.742500    1.205000              0.270000   \n",
       "50%     98.000000       2.355000    2.135000              0.340000   \n",
       "75%    107.000000       2.800000    2.875000              0.437500   \n",
       "max    162.000000       3.880000    5.080000              0.660000   \n",
       "\n",
       "       Proanthocyanins  Color intensity         Hue  \\\n",
       "count       178.000000       178.000000  178.000000   \n",
       "mean          1.590899         5.058090    0.957449   \n",
       "std           0.572359         2.318286    0.228572   \n",
       "min           0.410000         1.280000    0.480000   \n",
       "25%           1.250000         3.220000    0.782500   \n",
       "50%           1.555000         4.690000    0.965000   \n",
       "75%           1.950000         6.200000    1.120000   \n",
       "max           3.580000        13.000000    1.710000   \n",
       "\n",
       "       OD280/OD315 of diluted wines      Proline  \n",
       "count                    178.000000   178.000000  \n",
       "mean                       2.611685   746.893258  \n",
       "std                        0.709990   314.907474  \n",
       "min                        1.270000   278.000000  \n",
       "25%                        1.937500   500.500000  \n",
       "50%                        2.780000   673.500000  \n",
       "75%                        3.170000   985.000000  \n",
       "max                        4.000000  1680.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the baseline model performance without normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wine.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_wine['Class label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the original dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0, \n",
    "                                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 13)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 13)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, multi_class=&#x27;ovr&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, multi_class=&#x27;ovr&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, multi_class='ovr', solver='liblinear')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's train and test original dataset with LR\n",
    "# try C=0.1, 0.2 ... 1\n",
    "# penalty='l1' or 'l2'\n",
    "lr = LogisticRegression(penalty='l2', C=0.5, solver='liblinear', multi_class='ovr')\n",
    "# Note that C=1.0 is the default. You can increase\n",
    "# or decrease it to make the regulariztion effect\n",
    "# stronger or weaker, respectively.\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.967741935483871\n",
      "Test accuracy: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy:', lr.score(X_train, y_train))\n",
    "print('Test accuracy:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing features onto the same scale\n",
    "\n",
    "- two common approaches to bringing different features onto the same scale\n",
    "- normalize or standarize\n",
    "\n",
    "### normalization\n",
    "\n",
    "- rescaling the features to a range of [0, 1] (**min-max scaling**)\n",
    "- to normalize the features we can simply apply the min-max scaling to each feature column\n",
    "- new value, $x^{i}_{norm}$ of an example $x^i$ can be calculated as follows: \n",
    "    $x^{i}_{norm} = \\frac {x^i - x_{min}}{x_{max} - x_{min}}$\n",
    "- use `MinMaxScaler` implemented in scikit-learn - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "- let's noramalize and scale Wine dataset\n",
    "\n",
    "### standarization\n",
    "- some common ways are :**StandardScaler** and **RobustScaler**\n",
    "\n",
    "#### StandardScaler\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "- removes mean and scales features to unit variance\n",
    "- for each sample: $\\vec{x} = \\frac{(\\vec{x}-u)}{s}$ where $u$ = mean of feature values and $s$ = standard deviation of feature values\n",
    "- applied StandardScaler in previous chapters\n",
    "\n",
    "#### RobustScaler \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html\n",
    "- is robust to outliers and can be good choice if the dataset is prone to overfitting\n",
    "- removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range)\n",
    "    - range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's experiment with bothn normalization and standarization techniques\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "X_norm = mms.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84210526, 0.1916996 , 0.57219251, ..., 0.45528455, 0.97069597,\n",
       "        0.56134094],\n",
       "       [0.57105263, 0.2055336 , 0.4171123 , ..., 0.46341463, 0.78021978,\n",
       "        0.55064194],\n",
       "       [0.56052632, 0.3201581 , 0.70053476, ..., 0.44715447, 0.6959707 ,\n",
       "        0.64693295],\n",
       "       ...,\n",
       "       [0.58947368, 0.69960474, 0.48128342, ..., 0.08943089, 0.10622711,\n",
       "        0.39728959],\n",
       "       [0.56315789, 0.36561265, 0.54010695, ..., 0.09756098, 0.12820513,\n",
       "        0.40085592],\n",
       "       [0.81578947, 0.66403162, 0.73796791, ..., 0.10569106, 0.12087912,\n",
       "        0.20114123]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the normalized dataset\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0, \n",
    "                                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9596774193548387\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# let's traing and test normalized dataset with LR\n",
    "lr1 = LogisticRegression(penalty='l2', C=1, solver='liblinear', multi_class='ovr')\n",
    "# Note that C=1.0 is the default. You can increase\n",
    "# or decrease it to make the regularization effect\n",
    "# stronger or weaker, respectively.\n",
    "lr1.fit(X_train_norm, y_train_norm)\n",
    "print('Training accuracy:', lr1.score(X_train_norm, y_train_norm))\n",
    "print('Test accuracy:', lr1.score(X_test_norm, y_test_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's apply RobustScaler now\n",
    "rs = RobustScaler()\n",
    "X_robust = rs.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the robust scaled dataset\n",
    "X_train_robust, X_test_robust, y_train_robust, y_test_robust = train_test_split(X_robust, y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=5, \n",
    "                                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# let's traing and test robust dataset with LR\n",
    "lr2 = LogisticRegression(penalty='l1', C=1, solver='liblinear', multi_class='ovr')\n",
    "lr2.fit(X_train_robust, y_train_robust)\n",
    "print('Training accuracy:', lr2.score(X_train_robust, y_train_robust))\n",
    "print('Test accuracy:', lr2.score(X_test_robust, y_test_robust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting meaningful features\n",
    "- overfitting occurs when a model performs much better on a training dataset than the test dataset\n",
    "    - the model has high variance\n",
    "- common solutions to reduce the generalization errors are:\n",
    "    1. collect more training data\n",
    "    2. introduce a penalty for complexity via regularization\n",
    "    3. choose a simpler model with fewer parameters\n",
    "    4. reduce the dimensionality of the data\n",
    "- for regularized models in scikit-learn that support L1 regularization, we can simply set the `penalty` parameter to `'l1'` to obtain a sparse solution\n",
    "- `LogisticRegression` classifier is a regularized model\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential feature selection algorithms\n",
    "- select subset of the original features based on criteria such as accuracy\n",
    "- **dimensionality reduction** via feature selection is especially useful for unregularized models\n",
    "- dimensionaliry reduction can have many advantages in real-world applications\n",
    "    - cheaper to collect features\n",
    "    - faster computation\n",
    "    - avoid overfitting\n",
    "    - reduce the generalization error\n",
    "- sequential feature selection algorithms are a family of greedy search algorithms\n",
    "- a classic selection algorithm is **sequential backward selection**\n",
    "- two types of search algorithms can be employed\n",
    "    1. **greedy algorithm** can be used locally optimal choices at each state of a combinatorial search problem\n",
    "        - generally yields a suboptimal solution\n",
    "    2. **exhaustive search algorithms** evaluates all possible combinations and are guaranteed to find the optimal solution\n",
    "        - not feasible in practice due to computational complexity\n",
    "\n",
    "### Sequential Backward Selection (SBS) algorithm\n",
    "- can be called backward elimination\n",
    "- sequentially remove features from the full features subset until the new feature subspace contains the desired number of features\n",
    "- inorder to determine which feature is to be removed at each stage, we define a criterion function such as error rate, that we want to minimize\n",
    "\n",
    "### Sequential Forward Selection (SFS) algorithm\n",
    "- sequentially add features until the new feature subspace contains the desired number of features\n",
    "- inorder to determine which feature to add at each stage, we define a criterion function such as accuracy that we want to maximize or error rate that we want to minimize\n",
    "\n",
    "### SBS implementation\n",
    "- scikit learn doesn't provide sequential feature selection algorithm\n",
    "- we can implement one as shown below\n",
    "- safe clone the estimator - deep copy of the estimator parameters without copying any associated data\n",
    "- https://scikit-learn.org/0.16/modules/generated/sklearn.base.clone.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=0):\n",
    "        \"\"\"\n",
    "        estimator = model\n",
    "        k_features = minimum features\n",
    "        \"\"\"\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.scores_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=self.test_size,\n",
    "                             random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's test SBS implemenation using the KNN classifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# selecting features\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_robust, y)\n",
    "\n",
    "# plotting performance of feature subsets\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/04_08.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),\n",
       " (0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12),\n",
       " (0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11),\n",
       " (0, 1, 2, 3, 5, 6, 7, 8, 9, 10),\n",
       " (0, 1, 2, 3, 5, 6, 8, 9, 10),\n",
       " (0, 1, 2, 3, 5, 6, 8, 10),\n",
       " (0, 1, 2, 3, 5, 6, 10),\n",
       " (0, 1, 3, 5, 6, 10),\n",
       " (0, 3, 5, 6, 10),\n",
       " (0, 3, 6, 10),\n",
       " (0, 3, 6),\n",
       " (0, 6),\n",
       " (0,)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the smallest feature subset which yielded the 100% accuracy?\n",
    "list(sbs.subsets_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset index 8 has 5 best feature subset\n",
    "best = tuple(sbs.subsets_[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 3, 5, 9)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcohol', 'Ash', 'Alcalinity of ash', 'Total phenols',\n",
      "       'Color intensity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's print the acutal column/feature names\n",
    "print(df_wine.columns[1:][tuple([best])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9839\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate the performance of the KNN classifier on the original robust dataset\n",
    "knn.fit(X_train_robust, y_train_robust)\n",
    "print('Training accuracy: %.4f'%knn.score(X_train_robust, y_train_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.967741935483871\n",
      "Test accuracy: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# let's use the selected best feature subset to see if the accuracy is improved...\n",
    "knn.fit(X_train_robust[:, best], y_train_robust)\n",
    "print('Training accuracy:', knn.score(X_train_robust[:, best], y_train_robust))\n",
    "print('Test accuracy:', knn.score(X_test_robust[:, best], y_test_robust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scitkit-Learn - Sequential Feature Selector\n",
    "\n",
    "- scikit-learn provides `SequentialFeatureSelector` API\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector\n",
    "- a transformer that performs Sequential Feature Selection\n",
    "- it adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion\n",
    "- at each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine # same data set as the wine datase above\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's apply RobustScaler now\n",
    "rs = RobustScaler()\n",
    "X_robust = rs.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=5, direction='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(estimator=KNeighborsClassifier(),\n",
       "                          n_features_to_select=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(estimator=KNeighborsClassifier(),\n",
       "                          n_features_to_select=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(estimator=KNeighborsClassifier(),\n",
       "                          n_features_to_select=5)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.fit(X_robust, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False, False,  True, False, False,\n",
       "       False, False,  True, False])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol' 'ash' 'alcalinity_of_ash' 'flavanoids'\n",
      " 'od280/od315_of_diluted_wines']\n"
     ]
    }
   ],
   "source": [
    "# let's print the acutal column/feature names\n",
    "print(np.array(wine.feature_names)[sfs.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = sfs.transform(X_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 5)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X_selected, y, \n",
    "                             test_size=0.25, \n",
    "                             random_state=0, \n",
    "                             stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9699\n",
      "Test accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate the performance of the KNN classifier on the original robust dataset\n",
    "knn1.fit(X_train, y_train)\n",
    "print(f'Training accuracy: {knn1.score(X_train, y_train):.4f}')\n",
    "print(f'Test accuracy: {knn1.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature ranking\n",
    "- if the features are ranked based on their respective importances then the top features can be selected\n",
    "\n",
    "### Tree-based feature ranking and selection\n",
    "- there are several techniques for feature selection - https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "- tree-based estimaters and ensemble-based classifiers such as random forest can be used to compute impurity-based feature importances\n",
    "- Random Forest can be used to measure the importance of features as the averaged impurity decrease computed from all decision trees in the forest\n",
    "    - doesn't make any assumption on whether dataset is linearly separable\n",
    "- RF implentation of scikit-learn provides `feature_importances_` attribute after fitting `RandomForestClassifier`\n",
    "- the code below trains RF of 500 tress on Wine dataset and rank the 13 features by their respective importance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=0.2,\n",
    "                             random_state=1)\n",
    "    \n",
    "feat_labels = df_wine.columns[1:]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500,\n",
    "                                random_state=1)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# print all the features and their importances in highest to lowest importance\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "# plot the histogram bar chart\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/04_09.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing with SBS best features\n",
    "print(df_wine.columns[1:][tuple([best])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF feature ranking Gotcha\n",
    "- if two or more features are highly correlated, one feature may be ranked very highly while the information on the other feature(s) may not be fully captured\n",
    "- on the other hand, we don't need to be concerned about this problem if we are merely interested in the predictive performance of a model rather than the interpretation of feature importance values\n",
    "\n",
    "\n",
    "### Scikit-learn SelectFromModel Class\n",
    "\n",
    "- scikit-learn provides `SelectFromModel` class that selects features based on a user-specified threshold after model fitting\n",
    "- one caveat is you should know the threshold\n",
    "- e.g. we could use threshold to `0.1` and keep features whose importance is greater or equal to the feature\n",
    "    - RF would keep reduce the feature set to the five most important features for the Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(forest, threshold=0.1, prefit=True)\n",
    "X_selected = sfm.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of features that meet this (0.1) threshold criterion:', \n",
    "      X_selected.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top features meeting the threshold criterion\n",
    "for f in range(X_selected.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
